---
title: "A Guide to rmx"
author: "Matthias Kohl"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
bibliography: rmx.bib
vignette: >
  %\VignetteIndexEntry{A Guide to rmx}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{utf8}
---


## Introduction

Radius-minimax (rmx) estimators are a special class of optimally-robust statistical 
procedures [@Kohl2005; @Rieder2008]. It is a class of asymptotically linear 
estimators where infinitesimal (shrinking) neighborhoods around parametric models 
are assumed [@Rieder1994; @Ruckdeschel2006; @Kohl2010; @Kohl2012]. In addition, 
various diagnostic plots are included such as plots of influence functions, 
absolute and relative information and cniper points [@Kohl2005]. In addition
to these asymptotic optimal results we use finite-sample corrections based
on Monte-Carlo simulations [@Kohl2010a].


We first load the package.
```{r}
library(rmx)
```


## Normal location and scale
We first consider the estimation of mean and standard deviation (SD) of normal 
distributions. We use the chem dataset from package MASS.

```{r}
library(MASS)
data(chem)
```

We first have a look at the data by using a normal qq-plot.
```{r, fig.width=7, fig.height=7}
qqnorm(chem)
qqline(chem)
```

There is at least one clear outlier in the data. We compute mean, SD, median 
and MAD.

```{r}
mean(chem)
median(chem)
sd(chem)
mad(chem)
```

It's no surprise that mean and SD are strongly influenced by the clear outlier.
We now compute the rmx-estimator, where we assume between one and two outliers.

```{r}
rmx.chem <- rmx(chem, model = "norm", eps.lower = 1/24, eps.upper = 2/24)
rmx.chem
```

The results seem not be affected by the clear outlier. We take a closer look
at the result.

```{r}
coef(rmx.chem)
vcov(rmx.chem)
sqrt(diag(vcov(rmx.chem)))
bias(rmx.chem)
mse(rmx.chem)
```

As is also noted in the output, the covariance as well as the standard errors
are asymptotic values. Bias and MSE (mean squared error) correspond to the 
maximum asymptotic bias and MSE, respectively. A more comprehensive output 
containing the above values can be generated by function summary.

```{r}
summary(rmx.chem)
```

Since we expect outliers (wrong values) in the data, we also be aware of the
bias that is usually unavoidable in this case leading to the consideration of
MSE instead of (co)variance alone. For simplicity we restrict ourselves to 
MSE, but one could also consider a whole class of convex risks [@Ruckdeschel2004].

Next, we perform the diagnostics. We start with the calculation of cniper and
outlier region, respectively.

```{r}
cniper(rmx.chem)
outlier(rmx.chem)
```

That is, observations below 2.04 or above 4.39 can be considered as cniper points. 
If such points exist the rmx estimator can be expected to be (asymptotically) more 
precise than the respective maximum-likelihood (ML) estimator.

Any observation below 1.04 or above 5.39 is very unlikely from the assumed 
model and should be considered as an outlier. The probability to get a value
of 1.04 or more smaller, respectively 5.39 or larger is 0.1%.

```{r}
getCnipers(rmx.chem)
getOutliers(rmx.chem)
```

The dataset includes two cniper and one outlier point. We can also plot the
cniper region including the data points.

```{r, fig.width=7, fig.height=7}
plot(cniper(rmx.chem))
```

There are several more diagnostic plots. First, we plot the influence functions.

```{r, fig.width=7, fig.height=7}
ifPlot(rmx.chem)
```

The plot shows the two coordinates of the influence function (IF), which are the
IF for mean and SD. The plot also shows the (absolute) information (info) that 
is associated with each observation. The (absolute) information corresponds to 
the square of the length of the IF evaluated at the respective data point. 
In case of our rmx estimators the length of the influence function and hence 
the information is bounded. Consequently, a single observation can only have a 
bounded influence on the estimates. The orange and red vertical lines represent
the boundaries of the cniper and outlier regions, respectively.

We use the functions of packages ggplot2 and grid for plotting, where each plot 
function (invisibly) returns the respective plot object. Hence, we can also modify 
the plots afterwards by extending the plot objects. In our example, we want to 
restrict the x-axis.

```{r, fig.width=7, fig.height=7, warning = FALSE}
library(ggplot2)
library(gridExtra)
gg <- ifPlot(rmx.chem, plot = FALSE)
grid.arrange(gg[[1]] + xlim(1, 5), gg[[2]] + xlim(1, 5), nrow = 1)
```


We can also plot only the influence function.

```{r, fig.width=7, fig.height=7}
plot(rmx.chem$rmxIF)
```

The plot shows that the location component of the influence function is a 
re-descending functions. In the robust literature several estimators with 
re-descending influence functions have been proposed. For examples see Chapter 8 
of [@Kohl2005].

Next, we plot the (absolute) information.

```{r, fig.width=7, fig.height=7}
aiPlot(rmx.chem)
```

We can also plot the relative information, which shows how the information is
distributed for estimation of mean and SD.

```{r, fig.width=7, fig.height=7}
riPlot(rmx.chem)
```

We restrict the x-axis to get a better overview of the center region.

```{r, fig.width=7, fig.height=7, warning = FALSE}
gg <- riPlot(rmx.chem, plot = FALSE)
grid.arrange(gg[[1]] + xlim(1, 5), gg[[2]] + xlim(1, 5), nrow = 1)
```

We can see that values around the mean are rather uninformative and most of 
the information is used for estimating SD. Values around mean - SD and mean + SD 
are most informative for estimating mean. Moreover, the more extreme the 
observations are the more of the information is used for estimating SD. 

We can also compare the (absolute) information our rmx estimator attributes
to the data with respectie information of the ML estimator.

```{r, fig.width=7, fig.height=7}
iiPlot(rmx.chem)
```

Again, the scaling of the axis is stronly distrubed by the outlier. We repeat 
the plot where we restrict the y-axis.

```{r, fig.width=7, fig.height=7, warning=FALSE}
gg <- iiPlot(rmx.chem)
gg + ylim(0, 10) + xlim(0, 10)
```

The orange line represents the maximum information rmx is attributing to a 
single observation. The black line corresponds to the line y = x. Hence, in all
cases ML attributes higher information to the observations than rmx. 

We can also generate standard diagnostic plots, which are pp- and qq-plots.

```{r, fig.width=7, fig.height=7}
ppPlot(rmx.chem)
qqPlot(rmx.chem)
```

Furthermore, the density of the estimated model can be compared with the 
empirical density.

```{r, fig.width=7, fig.height=7}
dPlot(rmx.chem)
```

Based on the diagnostic plots, the normal distribution seems to fit well to 
the data, if we ignore at least the obvious outlier; that is, our inference
with the rmx approach should be reliable. Hence, we finally compute confidence 
intervals for the estimates.

```{r}
confint(rmx.chem)
confint(rmx.chem, method = "as.bias")
```

The first confidence interval ignores a potential bias and is only based on 
the asymptotic (co)variance. The second interval also takes the maximum 
asymptotic bias into consideration and therefore is more conservative.

As an alternative approach, we implemented also a bootstrap option based on
the functions of package boot.  

```{r}
confint(rmx.chem, method = "boot")
```

The bootstrap results are between the results of the asymptotic intervals with 
and without considering bias. 

For high-dimensional datasets such as omics-data there are also functions for
row- and column-wise computation of rmx estimators as developed for @Kohl2010a.

```{r}
M <- matrix(rnorm(100), nrow = 10)
rowRmx(M, eps.lower = 0, eps.upper = 0.05)
colRmx(M, eps.lower = 0, eps.upper = 0.05)
```



## sessionInfo
```{r}
sessionInfo()
```


## References